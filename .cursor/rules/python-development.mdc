---
description: Comprehensive Python development guidelines and coding standards for MoneyBin
alwaysApply: true
---

# Python Development Standards

## Core Development Principles

### Modern Practices

- Use the latest idiomatically correct approaches for each language/framework
- Link to current authoritative documentation for all framework-specific methods
- Maintain clean, readable, and maintainable code
- Implement proper error handling and logging

### Planning Process

1. **Verify Approach**: Research and validate technical approaches before implementation
2. **Create Plans**: Document implementation plans before making changes
3. **Minimize Edits**: Make targeted, minimal changes rather than broad rewrites
4. **Test Incrementally**: Validate each change before proceeding to the next

### Code Organization

- Prefer editing existing files over creating new ones
- Never create files unless absolutely necessary for the goal
- Use clear, descriptive naming conventions
- Organize code into logical modules and functions

## Technology Stack

### Primary Technologies

- **Database**: [DuckDB](https://duckdb.org/docs/) for analytical workloads
- **Data Processing**: Python for extraction and [DBT Core](https://docs.getdbt.com/) for transformation
- **PDF Processing**: Modern libraries like [pdfplumber](https://github.com/jsvine/pdfplumber), [tabula-py](https://github.com/chezou/tabula-py), or [camelot-py](https://github.com/camelot-dev/camelot)
- **Bank APIs**: [Plaid](https://plaid.com/docs/) for automated transaction aggregation (where possible)
- **Storage**: Local filesystem or user-controlled cloud storage
- **Visualization**: Integration-ready for dashboards and reporting tools

### Development Tools

- **Code Formatting**: [Ruff](https://docs.astral.sh/ruff/) for Python code formatting and linting
- **Type Checking**: [Pyright](https://microsoft.github.io/pyright/) for fast Python type checking
- **Package Management**: [uv](https://docs.astral.sh/uv/) for fast Python package management
- **Testing**: [pytest](https://docs.pytest.org/) for comprehensive testing
- **Orchestration**: [Dagster](https://docs.dagster.io/) for data pipeline orchestration

## Code Style & Formatting

### Ruff Code Formatter & Linter

- **Always use Ruff**: Code must be formatted and linted with [Ruff](https://docs.astral.sh/ruff/) (line length 88)
- **Auto-format**: Run `ruff format .` before committing
- **Auto-lint**: Run `ruff check .` before committing
- **IDE Integration**: Configure your editor to format on save with Ruff

### Naming Conventions

- **Files**: snake_case (`plaid_extractor.py`)
- **Classes**: PascalCase (`PlaidExtractor`)
- **Functions**: snake_case (`extract_transactions`)
- **Constants**: UPPER_SNAKE_CASE (`MAX_RETRY_ATTEMPTS`)
- **Variables**: snake_case (`transaction_data`)

### Import Organization (Ruff)

- **Standard Library**: Python built-in modules first
- **Third Party**: External packages (polars, dagster, etc.)
- **Local**: MoneyBin modules last
- **Grouping**: Separate groups with blank lines

```python
# Standard library imports
import os
import sys
from pathlib import Path
from typing import Any

# Third-party imports
import polars as pl
import duckdb
from dagster import asset, get_dagster_logger
from pydantic import BaseModel

# Local imports
from moneybin.extractors.plaid_extractor import PlaidExtractor
from moneybin.processors.data_processor import DataProcessor
```

### Import Statements

- **Absolute Imports**: Prefer absolute imports for clarity
- **Relative Imports**: Use relative imports only within packages
- **Avoid Wildcards**: Never use `from module import *`

```python
# Good - Absolute imports
from moneybin.extractors.plaid_extractor import PlaidExtractor

# Good - Relative imports within package
from .base_extractor import BaseExtractor

# Bad - Wildcard imports
from moneybin.extractors import *
```

## Type Hints & Annotations

### Required Type Hints

- **Function Parameters**: All parameters must have type hints
- **Return Values**: All functions must specify return types
- **Variables**: Use type hints for complex variables
- **Collections**: Specify types for lists, dicts, etc.

### Type Checking with Pyright

- **Use Pyright**: Fast type checking with [Pyright](https://microsoft.github.io/pyright/) instead of mypy
- **Strict Mode**: Configure Pyright in strict mode for comprehensive type checking
- **IDE Integration**: Enable Pyright in your editor for real-time type checking

```python
def process_transactions(
    transactions: list[dict[str, Any]],
    account_id: str,
    start_date: datetime | None = None
) -> pd.DataFrame:
    """Process transaction data and return standardized DataFrame."""
    pass

# Use type aliases for complex types
TransactionData = dict[str, str | float | datetime]
TransactionList = list[TransactionData]
```

### Type Annotation Verification Workflow

**ALWAYS verify type annotations by running pyright checks before considering implementation complete.**

#### Required Workflow:

1. **Add Type Annotations**: All functions, parameters, and return values must have type annotations
2. **Run Pyright**: Verify the specific file(s) you modified
3. **Fix Type Errors**: Address all type checking errors before committing
4. **Document Exceptions**: Use `# type: ignore[...]` comments only when necessary with clear explanations

#### Verification Commands:

```bash
# Check a specific file after editing
uv run pyright src/moneybin/config.py

# Check a specific module
uv run pyright src/moneybin/extractors/

# Check all test files
uv run pyright tests/

# Check entire codebase
uv run pyright
```

#### Common Type Annotations for Pytest Fixtures:

```python
from pathlib import Path
from pytest_mock import MockerFixture

def test_example(
    tmp_path: Path,              # Temporary directory fixture
    mocker: MockerFixture,        # Pytest-mock fixture
    caplog,                       # Type annotation not typically needed
):
    """Test with proper fixture type annotations."""
    pass
```

#### Type Ignore Comments (Use Sparingly):

When third-party library type stubs are incomplete or incorrect, use specific type ignore comments:

```python
# For specific type checking issues
result = some_library_call()  # type: ignore[reportUnknownMemberType]

# With explanation for why ignore is needed
conn = duckdb.connect(db_path)  # type: ignore[misc]
# DuckDB's type stubs don't define the config parameter correctly
```

#### Best Practices:

- **Never skip type checking** - Always run pyright on modified python files
- **Fix at the source** - Prefer adding proper types over ignoring errors
- **Explain ignores** - Always comment why a type ignore is necessary
- **Test fixtures** - Add type annotations for pytest fixtures (MockerFixture, Path, etc.)
- **Import types** - Import typing utilities as needed (Any, Literal, TypeVar, etc.)

### Pydantic Models

- **Data Validation**: Use [Pydantic](https://docs.pydantic.dev/) models for API responses and data structures
- **Field Validation**: Add constraints and validators where appropriate
- **Documentation**: Include field descriptions

```python
from pydantic import BaseModel, Field, field_validator
from datetime import datetime
from decimal import Decimal

class Transaction(BaseModel):
    """Financial transaction data model."""

    transaction_id: str = Field(..., description="Unique transaction identifier")
    account_id: str = Field(..., description="Associated account ID")
    date: datetime = Field(..., description="Transaction date and time")
    amount: Decimal = Field(..., description="Transaction amount (positive for income, negative for expense)")
    description: str = Field(..., description="Transaction description")
    category: str | None = Field(None, description="Transaction category")

    @field_validator('amount')
    @classmethod
    def validate_amount(cls, v):
        """Ensure amount is not zero."""
        if v == 0:
            raise ValueError('Amount cannot be zero')
        return v
```

## Project Structure & Organization

### Source Code Organization

```text
src/
├── moneybin/
│   ├── __init__.py
│   ├── extractors/          # Data extraction modules
│   │   ├── __init__.py
│   │   ├── plaid_extractor.py
│   │   ├── pdf_extractor.py
│   │   └── csv_processor.py
│   ├── processors/          # Data processing utilities
│   ├── validators/          # Data validation
│   ├── utils/               # Shared utilities
│   └── cli.py               # Command-line interface
```

## Error Handling & Logging

### Exception Handling

- **Specific Exceptions**: Catch specific exception types, not generic `Exception`
- **Meaningful Messages**: Provide clear error messages with context
- **Proper Logging**: Log errors with appropriate levels
- **User Feedback**: Provide clear, actionable error messages

```python
import logging

logger = logging.getLogger(__name__)

def safe_extract_data(file_path: str) -> pd.DataFrame | None:
    """Safely extract data from file with proper error handling."""
    try:
        if file_path.endswith('.csv'):
            return pd.read_csv(file_path)
        elif file_path.endswith('.pdf'):
            return extract_pdf_data(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_path}")

    except FileNotFoundError:
        logger.error(f"File not found: {file_path}")
        return None
    except pd.errors.EmptyDataError:
        logger.warning(f"Empty file: {file_path}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error processing {file_path}: {e}")
        raise
```

### Logging Configuration

- **Structured Logging**: Use structured logging for production
- **Log Levels**: Use appropriate levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- **Context**: Include relevant context in log messages

```python
import logging
from dagster import get_dagster_logger

logger = get_dagster_logger()

def process_bank_data(bank_name: str, account_count: int):
    logger.info("Starting bank data processing", extra={
        "bank_name": bank_name,
        "account_count": account_count,
        "operation": "data_processing"
    })

    try:
        # Processing logic here
        logger.info("Bank data processing completed successfully")
    except Exception as e:
        logger.error("Bank data processing failed", extra={
            "bank_name": bank_name,
            "error": str(e),
            "operation": "data_processing"
        })
        raise
```

## Testing Standards

### Test Organization

```text
tests/
├── unit/                    # Unit tests
│   ├── test_extractors/
│   ├── test_processors/
│   └── test_validators/
├── integration/             # Integration tests
├── fixtures/                # Test data and fixtures
└── conftest.py             # Pytest configuration
```

### Test Naming & Structure

- **Test Files**: Prefix with `test_` (`test_plaid_extractor.py`)
- **Test Functions**: Prefix with `test_` (`test_extract_transactions`)
- **Test Classes**: Prefix with `Test` (`TestPlaidExtractor`)
- **Descriptive Names**: Use descriptive test names that explain the scenario
- **Pytest**: Use [pytest](https://docs.pytest.org/) for all testing
- **Fixtures**: Create reusable fixtures for common test data
- **Mocking**: Use pytest-mock's mocker fixture for external dependencies
- **Coverage**: Aim for high test coverage (>80%)

```python
import pytest
from moneybin.extractors.plaid_extractor import PlaidExtractor

class TestPlaidExtractor:
    """Test suite for PlaidExtractor class."""

    @pytest.fixture
    def mock_plaid_client(self, mocker):
        """Mock Plaid client for testing."""
        return mocker.Mock()

    def test_extract_transactions_success(self, mock_plaid_client):
        """Test successful transaction extraction."""
        # Arrange
        extractor = PlaidExtractor(mock_plaid_client)
        mock_plaid_client.transactions_get.return_value = {
            'transactions': [{'id': '1', 'amount': 100.0}]
        }

        # Act
        result = extractor.extract_transactions('token', '2024-01-01', '2024-01-31')

        # Assert
        assert len(result) == 1
        assert result[0]['amount'] == 100.0

    def test_extract_transactions_empty_response(self, mock_plaid_client):
        """Test handling of empty transaction response."""
        # Arrange
        extractor = PlaidExtractor(mock_plaid_client)
        mock_plaid_client.transactions_get.return_value = {'transactions': []}

        # Act
        result = extractor.extract_transactions('token', '2024-01-01', '2024-01-31')

        # Assert
        assert result == []
```

## Financial Data Specific Rules

### Data Processing

- **Polars**: Use for high-performance data manipulation when needed
- **DuckDB**: Use [DuckDB](https://duckdb.org/docs/) for large data operations and analytics
- **Chunking**: Process large files in chunks to manage memory
- **Validation**: Always validate financial data before processing

```python
# Good - Vectorized operations
def process_transactions_vectorized(df: pd.DataFrame) -> pd.DataFrame:
    """Process transactions using vectorized operations."""
    df['amount_abs'] = df['amount'].abs()
    df['is_expense'] = df['amount'] < 0
    df['month'] = df['date'].dt.to_period('M')
    return df

# Good - Chunked processing for large files
def process_large_csv(file_path: str, chunk_size: int = 10000):
    """Process large CSV files in chunks."""
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        processed_chunk = process_transactions_vectorized(chunk)
        yield processed_chunk

# Good - DuckDB for large operations
def aggregate_transactions_duckdb(transactions_df: pd.DataFrame) -> pd.DataFrame:
    """Use DuckDB for efficient aggregation."""
    import duckdb

    conn = duckdb.connect(':memory:')
    conn.register('transactions', transactions_df)

    result = conn.execute("""
        SELECT
            strftime('%Y-%m', date) as month,
            category,
            SUM(amount) as total_amount,
            COUNT(*) as transaction_count
        FROM transactions
        GROUP BY month, category
        ORDER BY month DESC, total_amount DESC
    """).fetchdf()

    conn.close()
    return result
```

### Async Operations

- **API Calls**: Use async/await for I/O operations
- **Concurrent Processing**: Use asyncio.gather for parallel operations
- **Rate Limiting**: Implement rate limiting for external APIs

```python
import asyncio
import aiohttp

async def fetch_multiple_accounts(session: aiohttp.ClientSession, account_ids: list[str]):
    """Fetch multiple account balances concurrently."""
    async def fetch_account(account_id: str):
        async with session.get(f"/accounts/{account_id}") as response:
            return await response.json()

    # Process with rate limiting
    semaphore = asyncio.Semaphore(5)  # Max 5 concurrent requests

    async def fetch_with_rate_limit(account_id: str):
        async with semaphore:
            return await fetch_account(account_id)

    tasks = [fetch_with_rate_limit(account_id) for account_id in account_ids]
    return await asyncio.gather(*tasks)
```

## Security & Best Practices

### Environment Variables

- **Never Hardcode**: Never hardcode API keys or secrets
- **Use python-dotenv**: Load environment variables from .env files
- **Validate Configuration**: Validate required environment variables on startup

```python
import os
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ConfigDict
from pydantic_settings import BaseSettings

load_dotenv()

class Settings(BaseSettings):
    """Application settings with validation."""

    model_config = ConfigDict(
        env_file=".env",
        case_sensitive=False,
        extra="forbid"
    )

    plaid_client_id: str = Field(..., description="Plaid client ID")
    plaid_secret: str = Field(..., description="Plaid secret key")
    plaid_env: str = Field(default='sandbox', description="Plaid environment")
    duckdb_path: str = Field(default='data/duckdb/financial.db', description="DuckDB database path")

# Validate settings on import
try:
    settings = Settings()
except ValidationError as e:
    raise RuntimeError(f"Configuration error: {e}") from e
```

### Input Validation

- **Sanitize Inputs**: Always validate and sanitize external inputs
- **Type Checking**: Use type hints and runtime validation
- **SQL Injection**: Use parameterized queries with DuckDB

```python
def safe_query_transactions(account_id: str, start_date: str, end_date: str):
    """Execute safe SQL query with parameterized inputs."""
    import duckdb

    # Validate inputs
    if not account_id or not start_date or not end_date:
        raise ValueError("All parameters are required")

    # Use parameterized query to prevent SQL injection
    query = """
        SELECT * FROM transactions
        WHERE account_id = ?
        AND date BETWEEN ? AND ?
        ORDER BY date DESC
    """

    conn = duckdb.connect('data/duckdb/financial.db')
    result = conn.execute(query, [account_id, start_date, end_date]).fetchdf()
    conn.close()

    return result
```

## Documentation Standards

### Docstrings

- **Google Style**: Use Google-style docstrings for all public functions and classes
- **Type Information**: Include type information in docstrings
- **Examples**: Provide usage examples for complex functions

```python
def categorize_transaction(description: str, amount: float) -> str:
    """Categorize a transaction based on description and amount.

    Args:
        description: Transaction description text
        amount: Transaction amount (positive for income, negative for expense)

    Returns:
        str: Transaction category (e.g., 'Food', 'Transportation', 'Income')

    Raises:
        ValueError: If description is empty or amount is zero

    Example:
        >>> categorize_transaction("Grocery Store", -45.67)
        'Food'
        >>> categorize_transaction("Salary Deposit", 2500.00)
        'Income'
    """
    if not description.strip():
        raise ValueError("Description cannot be empty")

    if amount == 0:
        raise ValueError("Amount cannot be zero")

    # Categorization logic here
    description_lower = description.lower()

    if any(word in description_lower for word in ['grocery', 'food', 'restaurant']):
        return 'Food'
    elif any(word in description_lower for word in ['gas', 'uber', 'lyft', 'parking']):
        return 'Transportation'
    elif amount > 0:
        return 'Income'
    else:
        return 'Other'
```

### Documentation Requirements

- **Always link to authoritative documentation** when suggesting framework methods
- **Provide context and reasoning** for technical decisions
- **Document data sources, extraction methods, and transformation processes**
- **Maintain clear README files** and technical documentation
- **Add comprehensive docstrings** to methods and files

## Development Workflow

### Pre-commit Hooks

- **Install pre-commit**: `uv add --dev pre-commit && pre-commit install`
- **Automatic Checks**: Code formatting, linting, and type checking
- **Quality Gates**: Ensure code quality before commits

### Development Commands

```bash
# Development setup
uv sync --dev
pre-commit install

# Code quality
ruff format .
ruff check .
pyright

# Testing
pytest tests/
pytest --cov=src tests/

# Add dependencies (always use uv, not pip)
uv add package-name              # Add runtime dependency
uv add --dev package-name        # Add development dependency
```

### IDE Configuration

- **Ruff Integration**: Configure auto-formatting and linting on save with [Ruff](https://docs.astral.sh/ruff/getting-started/)
- **Type Checking**: Enable [Pyright](https://microsoft.github.io/pyright/) integration for fast type checking
- **Linting**: Ruff provides comprehensive linting
- **Auto-imports**: Ruff handles import organization automatically

## Compliance with MoneyBin Rules

### Data Ownership

- **Local Storage**: All financial data must be stored locally
- **No External Storage**: Use external APIs only for extraction, not storage
- **Privacy First**: Implement encryption for sensitive data

### Performance

- **Efficient Operations**: Use appropriate tools for data size
- **Memory Management**: Monitor memory usage for large datasets
- **Caching**: Implement caching where appropriate
- **Scalable Design**: Design for growing data volumes

### Error Handling

- **Graceful Degradation**: Handle failures with fallback options
- **User Experience**: Provide clear error messages and recovery steps
- **Monitoring**: Log all errors for debugging and monitoring
- **Robust Processing**: Implement robust error handling for all data extraction processes
- **Data Validation**: Validate extracted data against original sources

Follow these standards to ensure consistent, maintainable, and high-quality Python code in the MoneyBin project.
