---
description: Incremental data extraction and duplicate prevention standards
globs: ["src/extractors/**/*.py", "src/cli/commands/extract.py", "src/loaders/**/*.py"]
alwaysApply: false
---

# Incremental Data Extraction Standards

## Core Principles

- **Day-boundary extraction**: Only extract complete days for consistency
- **Incremental by default**: Avoid duplicate API calls unless forced
- **Metadata tracking**: Store extraction dates in primary database (DuckDB)
- **API cost optimization**: Minimize calls through intelligent caching

## Duplicate Prevention

- **Extraction level**: Track last extraction dates
- **Loading level**: Use unique IDs (transaction_id) to prevent duplicates
- **Storage level**: Allow duplicate raw files, deduplicate at database level

## Implementation Pattern

```python
def get_incremental_date_range(access_token: str) -> tuple[datetime | None, datetime | None]:
    """Calculate date range for incremental extraction.

    Returns (start_date, end_date) if new complete days available, (None, None) otherwise
    """
    last_extraction = get_last_extraction_date(access_token)
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)

    if last_extraction:
        potential_start = last_extraction + timedelta(days=1)
        if potential_start <= yesterday:
            return (potential_start, yesterday)
        else:
            logger.info("âœ… No new complete days - skipping API call")
            logger.info("ðŸ’° Saved API call")
            return (None, None)
    else:
        # First extraction - full lookback
        return (today - timedelta(days=lookback_days), yesterday)
```

## Force Override

```python
def extract_data(access_token: str, force: bool = False) -> DataFrame:
    """Extract with incremental logic, force override available."""
    if not force:
        start_date, end_date = get_incremental_date_range(access_token)
        if start_date is None:
            return empty_dataframe()  # No new data
    # Proceed with extraction...
```

## CLI Integration

```python
@app.command("extract")
def extract_command(force: bool = typer.Option(False, "--force", "-f")):
    """Extract with smart incremental logic (use --force for full)."""
    if force:
        logger.info("ðŸ”„ FORCED extraction - full lookback period")
    else:
        logger.info("ðŸ“ˆ INCREMENTAL extraction - only new days")
```

## Database Loading

```python
# Incremental load with deduplication
if incremental:
    conn.sql("""
        INSERT INTO transactions
        SELECT * FROM read_parquet('data/*.parquet')
        WHERE transaction_id NOT IN (SELECT transaction_id FROM transactions)
    """)
else:
    # Full refresh
    conn.sql("CREATE OR REPLACE TABLE transactions AS SELECT * FROM read_parquet('data/*.parquet')")
```

**Reference**: See `src/moneybin/extractors/plaid_extractor.py` for complete implementation
